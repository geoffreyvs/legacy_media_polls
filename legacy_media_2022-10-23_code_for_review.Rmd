---
title: "2022 Midterm Polling Situation Updated"
author: "Geoffrey Skelley"
date: "10/23/2022"
output: html_document
---

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache=TRUE)
setwd("/Users/skelg001/Documents/FiveThirtyEight/2022-10-20_MIDTERM_POLLS")
options(scipen=999)
```

```{r libraries, message = FALSE, warning = FALSE}
library(dplyr)
library(tidyr)
library(knitr)
library(lubridate)
library(ggplot2)

```

```{r base data}

elec_day <- read.csv("skelley.LEGACY-POLLS.1020 _ skelley.UNDERPOLLED.10TK - elecday.csv", stringsAsFactors = FALSE)

#generic ballot polls in midterms 2010-2022
gb22 <-read.csv("2022_gb_10-23.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2022)
gb18 <- read.csv("2018_gb.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2018)
gb14 <- read.csv("2014_gb.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2014)
gb10 <- read.csv("2010_gb.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2010)

gb1022 <- bind_rows(gb10, gb14, gb18, gb22) %>%
  mutate(type = "GB")

#House polls (of individual races) in midterms 2010-2022
house22 <- read.csv("2022_house_10-23.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2022)
house18 <- read.csv("2018_house.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2018)
house14 <- read.csv("2014_house.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2014)
house10 <- read.csv("2010_house.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2010)

house1022 <- bind_rows(house10, house14, house18, house22) %>%
  mutate(type = "H")

#Senate polls in midterms 2010-2022
sen22 <- read.csv("2022_sen_10-23.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2022)
sen18 <- read.csv("2018_sen.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2018)
sen14 <- read.csv("2014_sen.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2014)
sen10 <- read.csv("2010_sen_may.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2010)

sen1022 <- bind_rows(sen10, sen14, sen18, sen22) %>%
  mutate(type = "S")

#Governor polls in midterms 2010-2022
gov22 <- read.csv("2022_gov_10-23.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2022)
gov18 <- read.csv("2018_gov.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2018)
gov14 <- read.csv("2014_gov.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2014)
gov10 <- read.csv("2010_gov.csv", stringsAsFactors = FALSE) %>%
  dplyr::select(-url,	-source) %>%
  mutate(cycle = 2010)

gov1022 <- bind_rows(gov10, gov14, gov18, gov22) %>%
  mutate(type = "G")

#combine all polls
all1022 <- bind_rows(gb1022, house1022, sen1022, gov1022) %>%
  select(cycle, type, race_id, senate_class, house_district, special, everything())

#write.csv(all1022, "allpolls.csv")

#fix dates with lubridate
all1022$end_date <- mdy(all1022$end_date)
all1022$start_date <- mdy(all1022$start_date)
elec_day$election_day <- mdy(elec_day$election_day)
```

```{r cleaning}
#check number of primary polls that we have for some older cycles
primary1022 <- all1022 %>%
  filter(subpopulation == "d" | subpopulation == "r") #141 observations

#check to see what polls are marked as tracking
tracker1022 <- all1022 %>%
  filter(tracking == TRUE)

#clean to remove primary polls and turn blanks to NA
#remove banned pollsters
#remove special elections
clean1022 <- all1022 %>% 
  mutate_all(na_if,"") %>% #turn all blanks to NA
#clean to remove primary polls and turn blanks to NA
  filter(is.na(subpopulation)) %>% #removed 141 observations of primary polls
#remove banned pollsters
  filter(pollster_id != 403) %>% #Research 2000
  filter(pollster_id != 470) %>% #TCJ Research
  filter(pollster_id != 1484) %>% #Blumenthal Research Daily
  filter(pollster_id != 1493) %>% #KG Polling
#remove special and irregular congressional elections
#https://polls.538.io/admin/races?order=cycle_asc&page=3&q%5Bspecial_eq%5D=true&utf8=%E2%9C%93
  filter(race_id != 1799)	%>% #	FL-19	 0 ?s 04/13/10
  filter(race_id != 1798)	%>% #	PA-12	12 ?s 05/18/10
  filter(race_id != 9454) %>% #	GA-09	 0 ?s 05/11/10 jungle primary
  filter(race_id != 1794)	%>% #	IN-03	 0 ?s 11/02/10 concurrent special for expiring term
  filter(race_id != 1796)	%>% #	GA-09	 0 ?s 06/08/10 runoff
  filter(race_id != 1795)	%>% #	NY-29	 0 ?s 11/02/10 concurrent special for expiring term
  filter(race_id != 1519)	%>% #	IL-S3	 0 ?s 11/02/10 concurrent special for expiring term of Barack Obama's old seat
  filter(race_id != 1797)	%>% #	HI-01	 7 ?s 05/22/10
  filter(race_id != 1526)	%>% #	MA-S1	19 ?s 01/19/10
  filter(race_id != 1773)	%>% #	VA-07	 0 ?s 11/04/14 concurrent special for expiring term
  filter(race_id != 1774)	%>% #	NJ-01	 0 ?s 11/04/14 concurrent special for expiring term
  filter(race_id != 1775)	%>% #	NC-12	 0 ?s 11/04/14 concurrent special for expiring term
  filter(race_id != 1776)	%>% #	FL-19	 0 ?s 06/24/14
  filter(race_id != 1777)	%>% #	FL-13	 4 ?s 03/11/14
  filter(race_id != 1470) %>% # LA-S2 16 ?S 12/06/14 Senate runoff, don't want to double-count polls of this race, in a sense, since they'd have polls for the initial vote on Nov. 6
  filter(race_id != 1755)	%>% #	PA-07	 0 ?s 11/06/18 concurrent special for expiring term
  filter(race_id != 1754)	%>% #	PA-15	 0 ?s 11/06/18 concurrent special for expiring term
  filter(race_id != 1759)	%>% #	PA-18	13 ?s 03/13/18
  filter(race_id != 1753)	%>% #	NY-25	 1 ?s 11/06/18 concurrent special for expiring term
  filter(race_id != 1758)	%>% #	AZ-08	 6 ?s 04/24/18
  filter(race_id != 1752)	%>% #	MI-13	 0 ?s 11/06/18 concurrent special for expiring term
  filter(race_id != 6209)	%>% #	MS-S2	12 ?s 11/27/18 Senate special election runoff, don't want to double-count polls of this race, in a sense, since they'd have polls for the initial vote on Nov. 6
  filter(race_id != 1756)	%>% #	OH-12	15 ?s 08/07/18
  filter(race_id != 1757)	%>% #	TX-27	 0 ?s 06/30/18 jungle primary (final)
  filter(race_id != 9498)	%>% #	CA-22	 0 ?s 04/05/22 jungle primary
  filter(race_id != 9481)	%>% #	MN-01	 2 ?s 08/09/22
  filter(race_id != 9499)	%>% #	CA-22	 0 ?s 06/07/22 runoff
  filter(race_id != 9500)	%>% #	NE-01	 0 ?s 06/28/22
  filter(race_id != 9501)	%>% #	TX-34	 2 ?s 06/14/22 jungle primary (final)
  filter(race_id != 9503)	%>% #	NY-19	 5 ?s 08/23/22
  filter(race_id != 9480)	%>% #	CA-S3	 1 ?s 11/08/22 concurrent special for expiring term
  filter(race_id != 9451)	%>% #	FL-20	 0 ?s 01/11/22
  filter(race_id != 9537)	%>% #	NY-23	 0 ?s 08/23/22
  filter(race_id != 9496)	%>% #	AK-01	22 ?s 08/16/22
  filter(race_id != 9536) #2022 Virgin Islands gov, N/A

#add date of election 
clean1022 <- left_join(clean1022, elec_day) %>%
  #days from election var
  mutate(days_elec = time_length(end_date - election_day, unit = "days")) %>%
  filter(days_elec > -181 & days_elec < 1) #6 months out or less

```

```{r fte narrow to most exclusive type}

#reduce to one observation per poll of each type based on most exclusive sample population
filter1022 <- clean1022 %>%
  mutate(population_full = replace(population_full, is.na(population_full), "blank")) %>%
  mutate(pop_hierarchy = if_else(population == "lv" , 1,
                                if_else(population_full == "v", 2,
                                if_else(population_full == "rv", 3,
                                if_else(population_full == "a", 4, 
                                if_else(population_full == "blank", 5, 6)))))) %>%
  group_by(poll_id, type, state, race_id, senate_class, house_district) %>%
  dplyr::mutate(n = n()) %>%
  arrange(poll_id, type, state, race_id, senate_class, house_district, pop_hierarchy) %>%
  slice(1)
```

```{r manual keep that get cut by cleaning}

#overlap removal below cuts out a handful of polls that had 0-day overlaps that were actually of different samples (weren't tracking)
keep <- filter1022 %>%
  filter(poll_id ==   32732 | #2 races -- YouGov both CA-Sen and CA-Gov in 2010
           poll_id == 32831 | #1 race  -- Susquehanna FL-Gov (but no overlap for the FL-Sen poll, so drop that)
           poll_id == 32729 | #2 races -- YouGov both FL-Sen and FL-Gov in 2010
           poll_id == 32724 | #3 races -- YouGov both NY Senate races NY-Gov in 2010
           poll_id == 32734 | #2 races -- YouGov both OH-Sen and OH-Gov in 2010
           poll_id == 32731 | #2 races -- YouGov both PA-Sen and PA-Gov in 2010
           poll_id == 55891 | #1 race  -- Pew Research generic ballot in 2018
           poll_id == 56766 | #1 race  -- Politico/Morning Consult generic ballot in 2018 
           poll_id == 56614) %>%  #1 race  -- Politico/Morning Consult generic ballot in 2018
  filter(poll_id != 32831 | type != "S") %>%
  #select vars so it matches output from removing overlap
  dplyr::select(cycle:sponsors, methodology:population, tracking, internal:partisan,election_day:n) %>%
  dplyr::select(-n, -pop_hierarchy, -sponsor_candidate_id) %>%
  mutate(grouping_id = 9999)

```

```{r remove overlapping polls -- CAREFUL WITH THIS, TAKES A LOT OF TIME}

#Remove overlapping polls
#CAUTION, TAKES A LONG TIME TO RUN
limit1022a <- filter1022 %>%
  dplyr::select(cycle:sponsors, methodology:population, tracking, internal:partisan,election_day:n) %>%
  dplyr::select(-n, -pop_hierarchy, -sponsor_candidate_id) %>%
  arrange(cycle, type, race_id, pollster_id, sponsors, desc(start_date)) %>%
  group_by(cycle, type, race_id, pollster_id, sponsors) %>%
  # Create a grouping variable (unique ID)
    mutate(grouping_id = cur_group_id())
    #below is removed
    #mutate(max_start_date = max(start_date)) %>%
    #mutate(max_end_date = max(end_date)) %>%
    #mutate(poll_order = dense_rank(desc(end_date))) %>%  # Not needed but might be useful for checking
    #mutate(lagend01 = time_length(end_date - lag(start_date, 1), unit = "days")) %>% #difference between end dates of most recent poll and 1 before it 
    #mutate(lagend02 = time_length(end_date - lag(start_date, 2), unit = "days")) %>% #difference between end dates of most recent poll and 2 before it 
    #mutate(lagend03 = time_length(end_date - lag(start_date, 3), unit = "days")) %>% #difference between end dates of most recent poll and 3 before it 
    #mutate(lagend04 = time_length(end_date - lag(start_date, 4), unit = "days")) %>% #difference between end dates of most recent poll and 4 before it 
    #mutate(lagend05 = time_length(end_date - lag(start_date, 5), unit = "days")) %>% #difference between end dates of most recent poll and 5 before it 
    #mutate(lagend06 = time_length(end_date - lag(start_date, 6), unit = "days")) %>% #difference between end dates of most recent poll and 6 before it 
    #mutate(lagend07 = time_length(end_date - lag(start_date, 7), unit = "days")) #difference between end dates of most recent poll and 7 before it (no overlaps for pollster-sponsor after the 7th lag)

# Create an empty results data frame for removing overlapping polls
limit1022 <- data.frame()

# Keep the non-overlapping polls
# Note: This maximizes the number of polls over minimizing gaps between polls 
# (which is very computationally expensive)
for (j in 1:length(unique(limit1022a$grouping_id))) {
  
  # Get the unique grouping
  data <- limit1022a |>
    filter(grouping_id == unique(limit1022a$grouping_id)[j])
  
  # Get first start date for the grouping
  curr_start <- first(data$start_date)
  
  # Append the first row of data (most recent poll when arranged earlier)
  limit1022 <- bind_rows(limit1022, data[1, ])
  
  # If there's only 1 poll in the grouping, continue
  if(nrow(data) == 1) {
    next
  } else {
    
    # If there's more than 1 poll in the grouping, then check for non-overlapping
    for (i in 2:nrow(data)) {
      
      d <- data$end_date[i]
      
      # If iteration's end date is before curr_start --> non-overlapping
      # which is possible because they're arranged descending
      if(d < curr_start) {
        
        # Bind that iteration's (non-overlapping) row to the results
        limit1022 <- bind_rows(limit1022, data[i,])
        
        # Replace curr_start with earliest poll's start date that we have so far
        # in the loop
        curr_start <- data[i,]$start_date
        
      }
    }
  }
}

# Check
limit1022 |> head()

# Export results
write.csv(limit1022, "limit1022_no-overlap.csv", row.names = FALSE)

# Export full to compare
write.csv(limit1022a, "limit1022_with-overlap.csv", row.names = FALSE)

```                                 

#Legacy pollsters/sponsors, newspapers
```{r legacy media}
#add 15 observations we actually want to keep
limit1022b <- limit1022 %>%
  bind_rows(keep)

#divide sponsor_ids var so we can distinguish sponsors
spon1022 <- limit1022b %>%
  separate(sponsor_ids, c("spon_id1","spon_id2","spon_id3","spon_id4","spon_id5","spon_id6","spon_id7","spon_id8"), sep = ",")

spon1022$spon_id1 <- as.numeric(spon1022$spon_id1)
spon1022$spon_id2 <- as.numeric(spon1022$spon_id2)
spon1022$spon_id3 <- as.numeric(spon1022$spon_id3)
spon1022$spon_id4 <- as.numeric(spon1022$spon_id4)
spon1022$spon_id5 <- as.numeric(spon1022$spon_id5)
spon1022$spon_id6 <- as.numeric(spon1022$spon_id6)
spon1022$spon_id7 <- as.numeric(spon1022$spon_id7)
spon1022$spon_id8 <- as.numeric(spon1022$spon_id8)

#legacy media involved in polling directly, with pollster_id
legacy1022 <- spon1022 %>%
  mutate(legacy_pollster = if_else(pollster_id == 816, 1, #ABC News
                      if_else(pollster_id == 1704, 1, #ABC/WaPo
                      if_else(pollster_id == 1502, 1, #WaPo/KFF
                      if_else(pollster_id == 1460, 1, #WaPo/George Mason
                      if_else(pollster_id == 1296, 1, #Univ of Maryland/WaPo
                      if_else(pollster_id == 486, 1, #The Washington Post
                      if_else(pollster_id == 79, 1, #CBS News       
                      if_else(pollster_id == 80, 1, #New York Times/CBS News
                      if_else(pollster_id == 1424, 1, #Siena College/NYT Upshot
                      if_else(pollster_id == 160, 1, #Fox (Pulse Opinion Research)
                      if_else(pollster_id == 613, 1, #Associated Press/GfK
                      if_else(pollster_id == 28, 1, #Associated Press
                      if_else(pollster_id == 1360, 1, #AP/NORC       
                      if_else(pollster_id == 490, 1, #Time
                      if_else(pollster_id == 607, 1, 0)))))))))))))))) %>%  #LA Times
  
  #Legacy media as sponsors
  mutate(legacy_spon = if_else(spon_id1 %in% 379 | spon_id2 %in% 379 | spon_id3 %in% 379 | spon_id4 %in% 379, 1, #ABC News
                          if_else(spon_id1 %in% 132 | spon_id2 %in% 132 | spon_id3 %in% 132 | spon_id4 %in% 132, 1, #NBC News
                          if_else(spon_id1 %in% 133 | spon_id2 %in% 133 | spon_id3 %in% 133 | spon_id4 %in% 133, 1, #CBS News
                          if_else(spon_id1 %in% 134 | spon_id2 %in% 134 | spon_id3 %in% 134 | spon_id4 %in% 134, 1, #NYT
                          if_else(spon_id1 %in% 276 | spon_id2 %in% 276 | spon_id3 %in% 276 | spon_id4 %in% 276, 1, #WSJ
                          if_else(spon_id1 %in% 143 | spon_id2 %in% 143 | spon_id3 %in% 143 | spon_id4 %in% 143, 1, #CNN
                          if_else(spon_id1 %in% 149 | spon_id2 %in% 149 | spon_id3 %in% 149 | spon_id4 %in% 149, 1, #FOX News
                          if_else(spon_id1 %in% 135 | spon_id2 %in% 135 | spon_id3 %in% 135 | spon_id4 %in% 135, 1, #USAT
                          if_else(spon_id1 %in% 378 | spon_id2 %in% 378 | spon_id3 %in% 378 | spon_id4 %in% 378, 1, #WaPo
                          if_else(spon_id1 %in% 398 | spon_id2 %in% 398 | spon_id3 %in% 398 | spon_id4 %in% 398, 1, #AP
                          if_else(spon_id1 %in%  71 | spon_id2 %in%  71 | spon_id3 %in%  71 | spon_id4 %in%  71, 1, #Reuters
                          if_else(spon_id1 %in% 382 | spon_id2 %in% 382 | spon_id3 %in% 382 | spon_id4 %in% 382, 1, #Time
                          if_else(spon_id1 %in% 380 | spon_id2 %in% 380 | spon_id3 %in% 380 | spon_id4 %in% 380, 1, #Newsweek
                          if_else(spon_id1 %in% 300 | spon_id2 %in% 300 | spon_id3 %in% 300 | spon_id4 %in% 300, 1, #LAT
                          if_else(spon_id1 %in% 676 | spon_id2 %in% 676 | spon_id3 %in% 676 | spon_id4 %in% 676, 1, #USC/LAT
                          if_else(spon_id1 %in% 576 | spon_id2 %in% 576 | spon_id3 %in% 576 | spon_id4 %in% 576, 1, #CNBC
                          if_else(spon_id1 %in% 374 | spon_id2 %in% 374 | spon_id3 %in% 374 | spon_id4 %in% 374, 1, #MSNBC
                          if_else(spon_id1 %in%1745 | spon_id2 %in%1745 | spon_id3 %in%1745 | spon_id4 %in%1745, 1, #FOX Business
                          if_else(spon_id1 %in% 373 | spon_id2 %in% 373 | spon_id3 %in% 373 | spon_id4 %in% 373, 1, #NPR
                          if_else(spon_id1 %in% 520 | spon_id2 %in% 520 | spon_id3 %in% 520 | spon_id4 %in% 520, 1, #CSM
                          if_else(spon_id1 %in% 649 | spon_id2 %in% 649 | spon_id3 %in% 649 | spon_id4 %in% 649, 1, #UPI
                          if_else(spon_id1 %in%  96 | spon_id2 %in%  96 | spon_id3 %in%  96 | spon_id4 %in%  96, 1, #Bloomberg
                          if_else(spon_id1 %in% 516 | spon_id2 %in% 516 | spon_id3 %in% 516 | spon_id4 %in% 516, 1, #US News & WR
                          if_else(spon_id1 %in% 765 | spon_id2 %in% 765 | spon_id3 %in% 765 | spon_id4 %in% 765, 1, #PBS NH
                          if_else(spon_id1 %in%  38 | spon_id2 %in%  38 | spon_id3 %in%  38 | spon_id4 %in%  38, 1, #Univision
                          if_else(spon_id1 %in% 360 | spon_id2 %in% 360 | spon_id3 %in% 360 | spon_id4 %in% 360, 1, #McClatchy
                          if_else(spon_id1 %in% 540 | spon_id2 %in% 540 | spon_id3 %in% 540 | spon_id4 %in% 540, 1, #Gannett
                          if_else(spon_id1 %in% 507 | spon_id2 %in% 507 | spon_id3 %in% 507 | spon_id4 %in% 507, 1, #Atlantic Media
                          if_else(spon_id1 %in% 402 | spon_id2 %in% 402 | spon_id3 %in% 402 | spon_id4 %in% 402, 1, #Nat Journal (was part of Atlantic Media at one point)
                          if_else(spon_id1 %in% 320 | spon_id2 %in% 320 | spon_id3 %in% 320 | spon_id4 %in% 320, 1, 0))))))))))))))))))))))))))))))) %>% #Telemundo
  #final vars for identification
  #legacy media outlet involved in as sponsor or pollster
  mutate(legacy = if_else(legacy_pollster == 1 | legacy_spon == 1, 1, 0))
                                  
```

```{r past race ratings, most recent from same period we are at in 2022}
races <- read.csv("skelley.LEGACY-POLLS.1020 _ skelley.UNDERPOLLED.10TK - sen_gov_races.csv", stringsAsFactors = FALSE) %>%
  rename(class = office_seat_name) %>%
  dplyr::select(cycle, type, race_id, state, state_full, class, stage) %>%
  mutate(class = replace(class, class == "Class I", "i")) %>%
  mutate(class = replace(class, class == "Class II", "ii")) %>%
  mutate(class = replace(class, class == "Class III", "iii")) %>%
  mutate(class = replace(class, class == "", "G"))

sen_ratings <- read.csv("senate_ratings_1021.csv", stringsAsFactors = FALSE) %>%
  filter(cycle == 2010 | cycle == 2014 | cycle == 2018 | cycle == 2022) %>%
  dplyr::select(forecaster, cycle, date, state, class, call)

sen_ratings$date <- mdy(sen_ratings$date)

sen_ratings1022 <- left_join(sen_ratings, elec_day) %>%
  mutate(days_from = time_length(date - election_day, unit = "days")) %>%
  filter(days_from < -14) %>% #so before equivalent of Oct. 25, 2022
  arrange(forecaster, cycle, date, state, class) %>%
  group_by(forecaster, cycle, state, class) %>%
    slice(which.max(days_from)) %>%
  ungroup()

gov_ratings <- read.csv("governor_ratings_1021.csv", stringsAsFactors = FALSE) %>%
  filter(cycle == 2010 | cycle == 2014 | cycle == 2018 | cycle == 2022) %>%
  dplyr::select(forecaster, cycle, date, state, call)

gov_ratings$date <- mdy(gov_ratings$date)

gov_ratings1022 <- left_join(gov_ratings, elec_day) %>%
  mutate(days_from = time_length(date - election_day, unit = "days")) %>%
  filter(days_from < -14) %>% #so before equivalent of Oct. 25, 2022
  arrange(forecaster, cycle, date, state) %>%
  group_by(forecaster, cycle, state) %>%
    slice(which.max(days_from)) %>%
  mutate(class = "G") %>%
  ungroup() %>%
  filter(state != "VA" & state != "NJ")

ratings1022 <- bind_rows(sen_ratings1022, gov_ratings1022)

ratings1022races <- left_join(ratings1022, races) %>%
  filter(!is.na(state_full)) %>%
  dplyr::select(cycle, forecaster, type, race_id, state_full, class, date, call) %>%
  rename(state = state_full) %>%
  mutate(rating_num = if_else(call == "Currently Safe Democrat", -3,
                      if_else(call == "Solidly Democratic", -3,
                      if_else(call == "Solid Democratic", -3,
                      if_else(call == "Safe D", -3,
                      if_else(call == "Safe D/I", -3,
                      if_else(call == "Solid D", -3,
                      if_else(call == "Democrat Favored", -2,
                      if_else(call == "Likely Democratic", -2,
                      if_else(call == "Likely D", -2,
                      if_else(call == "Lean D", -1,
                      if_else(call == "Leans D", -1,
                      if_else(call == "Lean Democratic", -1,
                      if_else(call == "Lean Democrat", -1,
                      if_else(call == "Tilt Democratic", -0.5,
                      if_else(call == "Toss-up/Tilt Democrat", -0.5,
                      if_else(call == "Toss-up", 0,
                      if_else(call == "Pure Toss-up", 0,
                      if_else(call == "Toss-up/Lean runoff", 0,
                      if_else(call == "Toss/Runoff", 0,
                      if_else(call == "Toss-up/Tilt Republican", 0.5,
                      if_else(call == "Tilt Republican", 0.5,
                      if_else(call == "Lean R", 1,
                      if_else(call == "Leans R", 1,
                      if_else(call == "Lean Republican", 1,
                      if_else(call == "Republican Favored", 2,
                      if_else(call == "Likely Republican", 2,
                      if_else(call == "Likely R", 2,
                      if_else(call == "Currently Safe Republican", 3,
                      if_else(call == "Solidly Republican", 3,
                      if_else(call == "Solid Republican", 3,
                      if_else(call == "Safe R", 3,
                      if_else(call == "Solid R", 3, 99)))))))))))))))))))))))))))))))))

ratings_group <- ratings1022races %>%
  group_by(cycle, type, state, race_id) %>%
  summarize(
    median_rat = median(rating_num)
  )

```

```{r join polling data with ratings}

legacy1022ratings <- left_join(legacy1022, ratings_group)

#just make sure things look right
#random 2014 GA-Sen poll is NA that Mary will update on Monday or we'll adjust for it
legacy1022ratingsgovsen <- legacy1022ratings %>%
  filter(type == "S" | type == "G")

legacy1022ratingshousehb <- legacy1022ratings %>%
  filter(type == "H" | type == "GB")

```

```{r legacy sponsor data}

leg_polls <- legacy1022ratings %>%
  filter(legacy == 1) #limit to just polls involving legacy media for exploration

#limit sample to polls taken at same time point as in 2022, including all types
legacy_x_days <- legacy1022ratings %>%
  filter(days_elec < -15) #15 days out in 2022 is Oct. 23 

#numerator of polls by type that involve legacy media or don't
numerator_leg <- legacy_x_days %>%
  group_by(cycle, type, legacy) %>%
  summarize(
    count = n()
  )

numerator_leg <- as.data.frame(numerator_leg)

#denominator of all polls by type
denominator_leg <- legacy_x_days %>%
  group_by(cycle, type) %>%
  summarize(
    total = n()
  )

denominator_leg <- as.data.frame(denominator_leg)

#combine numerator and denominator
stats_leg <- full_join(numerator_leg, denominator_leg) %>%
  mutate(perc = (count/total) *100) %>%
  add_row(cycle = 2014, type = "H", legacy = 1, count = 0, total = 203, perc = 0) %>% #0 polls so no numerator, update when changing `days_elec`
  add_row(cycle = 2022, type = "H", legacy = 1, count = 0, total = 186, perc = 0) #0 polls so no numerator, update when changing `days_elec`

#data for chart on legacy polls
stats_leg_filt <- stats_leg %>%
  filter(legacy == 1)

chart.leg.perc <- ggplot(stats_leg_filt, aes(x = cycle, y = perc, group = type, color = type)) +
  geom_line() +
  scale_x_continuous(limits = c(2010, 2022),
                     breaks = c(2010, 2014, 2018, 2022))

chart.leg.perc

chart.leg.count <- ggplot(stats_leg_filt, aes(x = cycle, y = count, group = type, color = type)) +
  geom_line() +
  scale_x_continuous(limits = c(2010, 2022),
                     breaks = c(2010, 2014, 2018, 2022))

chart.leg.count


```

```{r chart of overall decline in polls}

#total polls conducted by type per cycle

total_polls <- denominator_leg %>%
  group_by(cycle) %>%
  summarize(
    sum_polls = sum(total)
  )

race_vs_gb <- denominator_leg %>%
  mutate(type2 = if_else(type == "GB", "GB", "Ind. Race")) %>%
  group_by(cycle, type2) %>%
  summarize(
    sum_polls = sum(total)
  )
  

race_vs_gb <- as.data.frame(race_vs_gb)

#chart.type <- ggplot(denominator_leg, aes(x = cycle, y = total, group = type, color = type)) +
  #geom_line() +
  #scale_x_continuous(limits = c(2010, 2022),
                     #breaks = c(2010, 2014, 2018, 2022))

#chart.type

chart.total <- ggplot(race_vs_gb, aes(x = cycle, y = sum_polls, group = type2, color = type2)) +
  geom_line() +
  scale_x_continuous(limits = c(2010, 2022),
                     breaks = c(2010, 2014, 2018, 2022))

chart.total

```

```{r partisan data}

#using same object that limits sample to polls taken at same time point as in 2022, including all types
partisan_x_days <- legacy_x_days %>%
  mutate(partisan_mark = if_else(!is.na(partisan), 1, 0)) %>% #mutate dummy var for whether poll was partisan or not
  mutate(internal_mark = if_else(!is.na(sponsor_candidate), 1, 0))

#numerator of polls by type that involve partisan sponsor/pollsters or not
numerator_part <- partisan_x_days %>%
  group_by(cycle, type, partisan_mark) %>%
  summarize(
    count = n()
  )

numerator_part <- as.data.frame(numerator_part)

#denominator of all polls by type
denominator_part <- partisan_x_days %>%
  group_by(cycle, type) %>%
  summarize(
    total = n()
  )

denominator_part <- as.data.frame(denominator_part)

#combine numerator and denominator
stats_part <- full_join(numerator_part, denominator_part) %>%
  mutate(perc = (count/total) *100)

#data for chart on partisan polls
stats_part_filt <- stats_part %>%
  filter(partisan_mark == 1)

chart.part.perc <- ggplot(stats_part_filt, aes(x = cycle, y = perc, group = type, color = type)) +
  geom_line() +
  scale_x_continuous(limits = c(2010, 2022),
                     breaks = c(2010, 2014, 2018, 2022))

chart.part.perc

#chart.part.count <- ggplot(stats_part_filt, aes(x = cycle, y = count, group = type, color = type)) +
  #geom_line() +
  #scale_x_continuous(limits = c(2010, 2022),
                     #breaks = c(2010, 2014, 2018, 2022))

#chart.part.count

#numerator of polls by type that involve partisan sponsor/pollsters or not
numerator_internal <- partisan_x_days %>%
  group_by(cycle, type, internal_mark) %>%
  summarize(
    count = n()
  )

numerator_internal <- as.data.frame(numerator_internal)

#combine numerator and denominator
stats_internal <- full_join(numerator_internal, denominator_part) %>%
  mutate(perc = (count/total) *100)  %>%
  filter(internal_mark == 1)

chart.internal.perc <- ggplot(stats_internal, aes(x = cycle, y = perc, group = type, color = type)) +
  geom_line() +
  scale_x_continuous(limits = c(2010, 2022),
                     breaks = c(2010, 2014, 2018, 2022))

chart.internal.perc

``` 

```{r how many Senate, Gov, House races have polls}

numerator_st_part <- partisan_x_days %>%
  filter(type != "GB") %>% #we're not interested in generic ballot polls for this
  group_by(cycle, state, type, house_district, race_id) %>% #race_id helps make things distinct for each individual race
  summarize(
    count = n()
  )

numerator_st_part <- as.data.frame(numerator_st_part)

denominator_st_part <- partisan_x_days %>%
  filter(type != "GB") %>%
  group_by(cycle, state, type, house_district) %>%
  summarize(
    total = n()
  )

denominator_st_part <- as.data.frame(denominator_st_part)

stats_st_part <- full_join(numerator_st_part, denominator_st_part) %>%
  mutate(perc = (count/total) *100)

state_cd_count <- denominator_st_part %>%
  group_by(cycle, type) %>%
  summarize(
    state_dist_count = n()
  )

state_cd_count <- as.data.frame(state_cd_count)

state_cd_count<- state_cd_count %>%
  mutate(total = c(37, 435, 37, 36, 435, 36, 36, 435, 35, 36, 435, 35)) %>%
  mutate(share_polled = (state_dist_count/total)*100)

#number of races with more than 1 poll:

two_plus <- denominator_st_part %>%
  filter(total > 1)

two_plus_count <- two_plus %>%
  group_by(cycle, type) %>%
  summarize(
    state_dist_count = n()
  )
```

```{r number of pollsters, overall vs competitive}

#overall
#numerator of polls per pollster by type
pollster_numerator <- partisan_x_days %>%
  filter(type != "GB") %>%
  group_by(cycle, type, pollster) %>%
  summarize(
    count = n()
  )

pollster_numerator <- as.data.frame(pollster_numerator)

pollster_denominator <- pollster_numerator %>%
  group_by(cycle, type) %>%
  summarize(
    sum_polls = sum(count)
  )

pollster_denominator <- as.data.frame(pollster_denominator)

pollster_totals <- left_join(pollster_numerator, pollster_denominator) %>%
  mutate(perc = (count/sum_polls)*100)

write.csv(pollster_totals, "pollster_totals.csv")

#number of polls per pollster
pollsters_cycle1 <- partisan_x_days %>%
  filter(type != "GB") %>%
  group_by(cycle, pollster) %>%
  summarize(
    count = n()
  )

pollsters_cycle2 <- pollsters_cycle1 %>%
  group_by(cycle) %>%
  summarize(
    n = n()
  )

#competitive statewide polls
polls_comp <- partisan_x_days %>%
  filter(type != "GB" | type != "H") %>%
  filter(!is.na(median_rat)) %>%
  mutate(competitive = if_else(median_rat <= 1 & median_rat >= -1, 1, 0))

polls_comp_group <- polls_comp %>%
  group_by(cycle, type, competitive) %>%
  summarize(
    poll_count = n()
  )

count_comp <- polls_comp %>%
  group_by(cycle, type, state, competitive) %>%
  summarize(
    count = n()
  )

count_comp_states <- count_comp %>%
  group_by(cycle, type, competitive) %>%
  summarize(
    num_states = n()
  )

polls_avg_comp_state <- left_join(polls_comp_group, count_comp_states) %>%
  mutate(avg_polls = poll_count/num_states)

#combine polls in competitive and uncompetitive races divided by number of states
    
#competitive statewide pollsters
pollsters_comp_group <- polls_comp %>%
  group_by(cycle, type, pollster, competitive) %>%
  summarize(
    count = n()
  )
  
```
